## 目录

* [概述](#%E6%A6%82%E8%BF%B0)
* [词典](#%E8%AF%8D%E5%85%B8)
* [封装](#%E5%B0%81%E8%A3%85)
* [视频](#%E8%A7%86%E9%A2%91)
  * [图片压缩](#%E5%9B%BE%E7%89%87%E5%8E%8B%E7%BC%A9)
  * [视频压缩](#%E8%A7%86%E9%A2%91%E5%8E%8B%E7%BC%A9)
* [音频](#%E9%9F%B3%E9%A2%91)
* [字幕](#%E5%AD%97%E5%B9%95)
  * [字幕文件](#%E5%AD%97%E5%B9%95%E6%96%87%E4%BB%B6)
  * [字幕类型](#%E5%AD%97%E5%B9%95%E7%B1%BB%E5%9E%8B)
* [字体](#%E5%AD%97%E4%BD%93)

## 概述

这篇文章讲解一些视音频相关的基础知识  
属于非常基础且易懂的科普，还是建议所有职位都学一学的

## 词典

* p=per=/（这是除号）  
  eg：4元每斤=4元p斤；Mbps=Mb/s

* k=10^3；M=10^6；G=10^9；Mi=1024^2；Gi=1024^3；Ti=1024^4  以此类推  
  tip：不写i属于不规范写法，但Windows等为了兼容性，仍用旧规范

* 比特=bit=b  
  字节=Byte=B  
  1B=8b

* 帧数，单位：f=frame=帧  
  帧率，单位：fps=帧每秒

* 二进制，每位能存2个值（0-1）  
  十进制，每位能存10个值（0-9）  
  eg：10位的二进制数有2^10=1024个，4位的十进制数有10^4=10000个  
  tip：常见的计算机用的存储器，每个位置只能存2个数，所以用二进制

* 采样，因为自然中的运动是连续的，但视音频无法记录每一刻的信息，所以只能每隔一段时间采样一次  
  eg：30fps的录像需要一秒采样30次或以上

## 封装

这里提出一点很多人的误解：很多人误以为一个视频文件，就必定包含音频。  

实际上视频文件和音频文件是分离的，平时我们看到的大多数视频文件，都是和一个音频文件“捆绑”在一起的。要实现这种“捆绑”，就需要使用容器，也就是封装。  

“容器”这个词非常形象，容器里可以放各种各样的文件。比如我可以在一个容器里塞2个视频、3个音频、4个字幕。  

常见的容器格式有mp4、mkv等。  

这里就得提到第二个跟多人的误区：mp4并不是视频格式，而是容器格式。  

假设一个mp4文件里有一个视频流，我可以把这个视频流抽出来，放在mkv容器里，而这个视频流本身是不会有变化的，变化的仅仅是容器格式。  

这里出现了第一个需要解释的词`流`，这个词也十分形象——播放中的视频，不就是流动的画面嘛。当然，你也可以叫它`轨道`，网上的叫法各种各样，但总之，一个容器里可以放很多的流。  

（mkv里甚至能塞入各种附件，如字体文件）  

**总结**：视音频等文件被封装在一个容器文件中。  

## 视频

大家应该听过一种说法，视频是由一张张图片组成的，但这种说法可能会导致大家忽视了视频的帧间压缩。  

视频的每一张图片被称作一帧，图片播放速率被称作帧率（别说成帧数了啊，帧数是视频的总图片数）——以上仅仅是类比，因为视频文件压根就不是一张张图片组成的。  

为什么？原因很简单，因为图片太大了！  

### 图片压缩

假设世界上有256种颜色，那么要用一个数值来表达一个像素，每个这种数值就需要占用256个存储位置，一个位置为1bit，256=2^8，8bit=1Byte，那么就是每个像素占用1B——这就是8bits色深的图片。（8bits位深的RGB图片是24bits色深）  

假设一张图片1920\*1080=2073600个像素，需要占用约2MB。但显然，平常我们见到的8位(即32bits色深，这里算上了透明通道，假设这里的透明通道也是8bits)的1080p图片理论上体积应该大于2MB^(32/8)=16MB，但实际只有约100KB，这是怎么回事？  

如果现在让你想一种方法，把原来2MB的图片尽量压缩得小，你会怎么做？是不是第一反应是，把大片大片同样颜色的区域用一个代表颜色的值、和一个代表形状和位置的值来表示？比如图片中央有一个800*800的白色正方形，本来需要用640000B表示的白色正方形，最终只用了几B就表示出来了。  

以上就是无损压缩，只不过实际上的无损压缩算法比这复杂得多。  

常见的无损压缩格式有PNG、GIF、TIFF、BMP、WEBP、RAW、HEIF等。  

那么有损压缩又是怎么一回事？  

假设现在有一大片(200,0,0)色的区域，里面混杂了一点(201,0,0)色的像素，因为这两种颜色过于接近，是不是可以把它们视作同一种颜色存储起来？反正肉眼看不出来嘛，能压缩成多小就压缩多小。  

但这样，原本的(201,0,0)色像素就丢失了，这不就是“有损”嘛。  

当然，实际上的有损压缩算法远比这复杂，大家能理解啥是有损就好。  

常见的有损压缩格式有JPEG、WEBP、HEIF、AVIF等。  

### 视频压缩

关于视频压缩，很多人存在误区：视频压缩就是一张张压缩后的图片拼接在一起的。  

如果仅仅是图片压缩后拼接，就如上文提到的，一张1080p8bits的图片体积约100KB=800Kb，假如一个视频30fps，那么码率就来到了惊人的24Mbps！  

要知道，流媒体平台上的4K视频，很多也不到20Mbps。所以如果仅仅是图片压缩后拼接，那么结果就是硬盘爆炸。  

所以聪明的你现在应该已经想到了帧间压缩了吧——因为视频的运动是连续的，所以赋予上个画面中的一部分一个矢量信息，那么它就能动起来了！如果一个物体匀速运动了30f，那么我们只用了1f的大小，就存储了30f的信息！  

常见视频格式有AVC、HEVC、AV1等。  

（常见的视频压缩格式都是有损的，不过大多支持无损模式，需要看编码器支不支持无损模式）  

**总结**：视频文件是经过复杂的算法压缩的，不仅仅是简单的图像堆叠。  

## 音频

与视频记录每个像素的颜色一样，音频记录的是每个采样点的响度与频率，把一个个采样点的坐标串起来，就还原了原本波的形状。  

如一个函数y=sinx，采样到了(0,0)，(π/2,1)，(π,0)三个坐标，那么生成的结果就是x∈(0,π)时的sinx图像。（实际上比这复杂很多）  

常见无损格式有FLAC、WAV(PCM)等。  

常见有损格式有AAC、MP3、OGG、OPUS等。  

## 字幕

### 字幕文件

字幕需要的是什么？起始点和结束点！  

所以字幕文件本质上就是赋予一串字符起始点和结束点。  

字幕样式就是规定字符串的字体、位置、运动等信息。大部分字幕格式是无法指定高级样式的。  

当然实际上还是比较复杂的，有兴趣的朋友可以打开一个字幕文件看看里面的结构。  

常见格式有SRT、ASS/SSA等。  

以上是文本字幕，本质上是把字符渲染成图形实现的；除此之外还有图形字幕，本质上就是图片，因为很少见，就不例举了。  

### 字幕类型

外挂字幕：字幕文件不在容器内，是单独的一个文件。  

内封/内挂/内置字幕：字幕文件封装在容器内，通常使用mkv封装，因为能同时封装字体。  

内嵌字幕：不存在字幕文件，字幕是视频画面的一部分。  

这里指的字幕类型是相对于视频来说的，如果不存在视频，那就没有所谓“字幕类型”；比如“外挂”是相对于视频来说是外挂，“内封”是相对视频来说是和视频封装在一起的。  

## 字体

字体是用来规定字符的图形的。  

比如`1`这个字符，你能看到它呈现的是`1`这个形状，是因为它的字体是这个形状，如果它的字体对应的字形是`2`，那么你输入`1`将看到`2`。  

Windows需要安装字体，右键字体文件安装即可，安装的字体文件将被复制到存放字体的文件夹中。当播放器播放字幕时，字幕渲染器(即字幕滤镜)会发现字幕文件里需要某个字体，这时会让系统调用已安装的那个字体。如果那个字体没被安装，播放器将按照默认字体渲染字幕。  

Android和iOS无法像Windows这样方便地安装字体，它们的字体渲染逻辑区别很大，所以有的Android播放器加载字体缓存能用到十几二十分钟，Android用户建议使用MPV系播放器解决字体加载问题。  

因为每个字体的字形大小可能会不一样，所以如果没能加载对应的字体，不仅会影响字幕观感，甚至可能会出现字幕超出屏幕边缘的情况。  
